{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "# generate all sequences by composition\n",
    "n = 20\n",
    "allow_symmetry = True\n",
    "all_seq_by_frac = {k: set() for k in range(n+1)}\n",
    "limit = 2**n\n",
    "for i in range(limit):\n",
    "    sequence = bin(i)[2:].zfill(n)\n",
    "    mirror_sequence = sequence[::-1]\n",
    "    if sequence <= mirror_sequence or allow_symmetry:\n",
    "        all_seq_by_frac[sequence.count('1')].add(sequence)\n",
    "\n",
    "# create a master list of all possible sequences\n",
    "all_sequences = []\n",
    "for k, v in all_seq_by_frac.items():\n",
    "    all_sequences += v\n",
    "print(f'generated {len(all_sequences)} sequences')        \n",
    "\n",
    "possible_sequences = np.array(list(all_seq_by_frac[8]))\n",
    "\n",
    "# load the model ensemble\n",
    "model_ensemble = []\n",
    "model_path = os.path.join('models', 'gru-opt-cv10-sym')\n",
    "for i in range(10):\n",
    "    model = torch.jit.load(os.path.join(model_path, f'fold-{i:02d}-scripted.pt'), map_location='cpu')\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17c74fba2df440b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble, model_selection\n",
    "\n",
    "\n",
    "class EnsembleRFModel(object):\n",
    "\n",
    "    def __init__(self, n_models=3, constructor=ensemble.RandomForestRegressor, model_params={}, symmetrize=False):\n",
    "        self.n_models = n_models\n",
    "        self.model_params = model_params\n",
    "        self.symmetrize = symmetrize\n",
    "        self.models = [constructor(**self.model_params) for _ in range(self.n_models)]\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        cv = model_selection.KFold(n_splits=self.n_models, shuffle=True, random_state=0)\n",
    "        for i, (fold_train_idx, fold_val_idx) in enumerate(cv.split(x)):\n",
    "            if self.symmetrize:\n",
    "                this_x = x[fold_train_idx]\n",
    "                this_x = np.vstack([this_x, [it[::-1] for it in this_x]])\n",
    "                this_y = y[fold_train_idx]\n",
    "                this_y = np.hstack([this_y, this_y])\n",
    "                _ = self.models[i].fit(this_x, this_y)\n",
    "            else:\n",
    "                _ = self.models[i].fit(x[fold_train_idx], y[fold_train_idx])\n",
    "        return self\n",
    "\n",
    "    def predict(self, x, return_std=False):\n",
    "        \n",
    "        if self.symmetrize:\n",
    "            all_yf = np.vstack([it.predict(x).reshape(1, -1) for it in self.models])\n",
    "            all_yr = np.vstack([it.predict([it[::-1] for it in x]).reshape(1, -1) for it in self.models])\n",
    "            all_y = 0.5 * (all_yf + all_yr)\n",
    "        else:\n",
    "            all_y = np.vstack([it.predict(x).reshape(1, -1) for it in self.models])\n",
    "\n",
    "        if return_std:\n",
    "            return np.mean(all_y, axis=0), np.std(all_y, axis=0)\n",
    "        else:\n",
    "            return np.mean(all_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tqdm.notebook\n",
    "\n",
    "\n",
    "def swap_monomers(seq):\n",
    "    seq = seq.replace('A', 'C')\n",
    "    seq = seq.replace('B', 'A')\n",
    "    seq = seq.replace('C', 'B')\n",
    "    return seq\n",
    "\n",
    "\n",
    "def make_base(degree, verbose=False):\n",
    "    # construct unique numbers of A/B monomers\n",
    "    base = []\n",
    "    for i in range(degree+1):\n",
    "        for j in range(i):\n",
    "            seq = ''.join(['A' for _ in range(i-j)] + ['B' for _ in range(j)])\n",
    "            base += [''.join(x) for x in itertools.permutations(seq)]\n",
    "            base += [''.join(x) for x in itertools.permutations(swap_monomers(seq))]\n",
    "    base = sorted(set(base))\n",
    "    pruned_base = []\n",
    "    for b in base:\n",
    "        if b not in pruned_base and b[::-1] not in pruned_base:\n",
    "            pruned_base.append(b)\n",
    "    base = pruned_base\n",
    "    if verbose:\n",
    "        print(f'Finding {len(base)} patterns:', base)\n",
    "\n",
    "    return base\n",
    "\n",
    "\n",
    "def featurize(chain_sequences, base, symmetric=False, verbose=False):\n",
    "    x = np.zeros([len(chain_sequences), len(base)])\n",
    "    pbar = tqdm.notebook.tqdm(enumerate(chain_sequences),\n",
    "                              total=len(chain_sequences),\n",
    "                              disable=(not verbose))\n",
    "    for i, chain in pbar:\n",
    "        if 'A' in str(chain):\n",
    "            seq = chain\n",
    "        else:\n",
    "            seq = ''.join(['A' if x == 0 else 'B' for x in chain])\n",
    "        x[i] = np.array([seq.count(b) for b in base])\n",
    "        if symmetric:\n",
    "            x[i] += np.array([seq[::-1].count(b) for b in base])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "base = make_base(degree=4)\n",
    "possible_tokens = featurize(possible_sequences, base, symmetric=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5b68d474c767139"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_prompt = \"Here\\n<result>\\nNote\"  # an empty/fake prompt to facilitate the message_utils\n",
    "AB = {'A': 0, 'B': 1}\n",
    "all_arrs = np.array([[int(x) for x in s] for s in possible_sequences])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a96e5433fc65bb3b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import message_utils, model_utils\n",
    "from target_defs import archetype_predictions, archetype_sequences\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "\n",
    "arch_morphs = list(archetype_predictions.keys())\n",
    "for morph in arch_morphs:\n",
    "    \n",
    "    target = archetype_predictions[morph]\n",
    "    \n",
    "    rollouts = []\n",
    "    \n",
    "    n_batch = 5\n",
    "    n_init = 5\n",
    "    n_total = 10\n",
    "    xi = 0\n",
    "    \n",
    "    use_tokens = False\n",
    "    symmetrize = False\n",
    "    use_seed = False\n",
    "    \n",
    "    params = {'n_batch': n_batch,\n",
    "            'n_init': n_init,\n",
    "            'xi': xi,\n",
    "            'use_tokens': use_tokens,\n",
    "            'symmetrize': symmetrize,\n",
    "            'target': target.tolist(),\n",
    "            'morph': morph,\n",
    "            'use_seed': use_seed}\n",
    "    \n",
    "    start_time = int(time.time())\n",
    "    for ridx in range(5):\n",
    "        fake_payload = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"N/A\"}]}]\n",
    "        \n",
    "        # rf = ensemble.RandomForestRegressor(random_state=0)\n",
    "        rf = EnsembleRFModel(model_params={'random_state': ridx, 'n_estimators': 24, 'max_depth': 6}, symmetrize=(symmetrize and not use_tokens))\n",
    "        \n",
    "        rng = np.random.RandomState(ridx)\n",
    "        init_idx = rng.choice(np.arange(len(possible_sequences)), n_init, replace=False)\n",
    "        init_bitstr = [possible_sequences[it] for it in init_idx]\n",
    "        if use_seed:\n",
    "            init_bitstr[0] = archetype_sequences[morph]\n",
    "        init_sequences = [it.replace('0', 'A').replace('1', 'B') for it in init_bitstr]\n",
    "        \n",
    "        if use_tokens:\n",
    "            x_so_far = featurize(init_sequences, base, symmetric=True)\n",
    "        else:\n",
    "            x_so_far = np.array([[int(AB[x]) for x in s] for s in init_sequences])\n",
    "        \n",
    "        out = model_utils.evaluate_sequences(init_sequences, target, model_ensemble)\n",
    "        fake_payload.append(message_utils.build_user_message(batch_prompt, out))\n",
    "        y_so_far = np.array([float(it.split(':')[1]) for it in out.split('\\n')])\n",
    "        \n",
    "        _ = rf.fit(x_so_far, y_so_far)\n",
    "        \n",
    "        is_avail = np.ones(len(possible_sequences)).astype(bool)\n",
    "        is_avail[init_idx] = False\n",
    "        \n",
    "        for _ in tqdm.tqdm(range(n_total-n_init//n_batch)):\n",
    "            \n",
    "            if use_tokens:\n",
    "                mu, sigma = rf.predict(possible_tokens, return_std=True)\n",
    "            else:\n",
    "                mu, sigma = rf.predict(all_arrs, return_std=True)\n",
    "    \n",
    "            o = np.hstack([np.argsort(mu - xi * sigma)])\n",
    "            next_sequences = []\n",
    "            k = 0\n",
    "            while len(next_sequences) < n_batch:\n",
    "                if is_avail[o[k]]:\n",
    "                    next_bitstr = possible_sequences[o[k]]\n",
    "                    seq = next_bitstr.replace('0', 'A').replace('1', 'B')\n",
    "                    next_sequences.append(seq)\n",
    "                    is_avail[o[k]] = False\n",
    "                k += 1\n",
    "            \n",
    "            if use_tokens:\n",
    "                next_x = featurize(next_sequences, base, symmetric=True)\n",
    "            else:\n",
    "                next_x = np.array([[int(AB[x]) for x in s] for s in next_sequences])\n",
    "            x_so_far = np.vstack([x_so_far, next_x])\n",
    "            \n",
    "            out = model_utils.evaluate_sequences(next_sequences, target, model_ensemble)\n",
    "            fake_payload.append(message_utils.build_user_message(batch_prompt, out))\n",
    "            y_so_far = np.hstack([y_so_far, np.array([float(it.split(':')[1]) for it in out.split('\\n')])])\n",
    "            \n",
    "            _ = rf.fit(x_so_far, y_so_far)\n",
    "        \n",
    "        buffer = {'params': params, 'messages': fake_payload}\n",
    "        suffix = str(ridx)\n",
    "        logfile = f'logs/active-learning-{start_time}{suffix}.json'\n",
    "        with open(logfile, 'w') as fid:\n",
    "            json.dump(buffer, fid)\n",
    "\n",
    "        rollouts.append(fake_payload)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a68fe27875fcb33e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
