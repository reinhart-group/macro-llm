{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 524800 sequences\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "# generate all sequences by composition\n",
    "n = 20\n",
    "allow_symmetry = False\n",
    "all_seq_by_frac = {k: set() for k in range(n+1)}\n",
    "limit = 2**n\n",
    "for i in range(limit):\n",
    "    sequence = bin(i)[2:].zfill(n)\n",
    "    mirror_sequence = sequence[::-1]\n",
    "    if sequence <= mirror_sequence or allow_symmetry:\n",
    "        all_seq_by_frac[sequence.count('1')].add(sequence)\n",
    "\n",
    "# create a master list of all possible sequences\n",
    "all_sequences = []\n",
    "for k, v in all_seq_by_frac.items():\n",
    "    all_sequences += v\n",
    "print(f'generated {len(all_sequences)} sequences')        \n",
    "\n",
    "possible_init_sequences = np.array(sorted(all_seq_by_frac[8]))  # without sort the order is NOT guaranteed\n",
    "\n",
    "# load the model ensemble\n",
    "model_ensemble = []\n",
    "model_path = os.path.join('models', 'gru-opt-cv10-sym')\n",
    "for i in range(10):\n",
    "    model = torch.jit.load(os.path.join(model_path, f'fold-{i:02d}-scripted.pt'), map_location='cpu')\n",
    "    model.eval()\n",
    "    model_ensemble.append(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T12:20:06.305529Z",
     "start_time": "2024-08-28T12:20:05.782683Z"
    }
   },
   "id": "17c74fba2df440b9"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated 1048576 sequences\n"
     ]
    }
   ],
   "source": [
    "# generate all sequences by composition\n",
    "n = 20\n",
    "all_seq_by_frac = {k: set() for k in range(n+1)}\n",
    "limit = 2**n\n",
    "for i in range(limit):\n",
    "    sequence = bin(i)[2:].zfill(n)\n",
    "    all_seq_by_frac[sequence.count('1')].add(sequence)\n",
    "\n",
    "# create a master list of all possible sequences\n",
    "all_sequences = []\n",
    "for k, v in all_seq_by_frac.items():\n",
    "    all_sequences += v\n",
    "print(f'generated {len(all_sequences)} sequences')        \n",
    "\n",
    "possible_sequences = np.array(sorted(all_seq_by_frac[8]))  # without sort the order is NOT guaranteed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T12:20:07.499615Z",
     "start_time": "2024-08-28T12:20:07.022318Z"
    }
   },
   "id": "4a8f2bca05299f29"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-28T12:20:08.888580Z",
     "start_time": "2024-08-28T12:20:08.882300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble, model_selection\n",
    "\n",
    "\n",
    "class EnsembleRFModel(object):\n",
    "\n",
    "    def __init__(self, n_models=3, constructor=ensemble.RandomForestRegressor, model_params={}, symmetrize=False):\n",
    "        self.n_models = n_models\n",
    "        self.model_params = model_params\n",
    "        self.symmetrize = symmetrize\n",
    "        self.models = [constructor(**self.model_params) for _ in range(self.n_models)]\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        cv = model_selection.KFold(n_splits=self.n_models, shuffle=True, random_state=0)\n",
    "        for i, (fold_train_idx, fold_val_idx) in enumerate(cv.split(x)):\n",
    "            if self.symmetrize:\n",
    "                this_x = x[fold_train_idx]\n",
    "                this_x = np.vstack([this_x, [it[::-1] for it in this_x]])\n",
    "                this_y = y[fold_train_idx]\n",
    "                this_y = np.hstack([this_y, this_y])\n",
    "                _ = self.models[i].fit(this_x, this_y)\n",
    "            else:\n",
    "                _ = self.models[i].fit(x[fold_train_idx], y[fold_train_idx])\n",
    "        return self\n",
    "\n",
    "    def predict(self, x, return_std=False):\n",
    "        \n",
    "        if self.symmetrize:\n",
    "            all_yf = np.vstack([it.predict(x).reshape(1, -1) for it in self.models])\n",
    "            all_yr = np.vstack([it.predict([it[::-1] for it in x]).reshape(1, -1) for it in self.models])\n",
    "            all_y = 0.5 * (all_yf + all_yr)\n",
    "        else:\n",
    "            all_y = np.vstack([it.predict(x).reshape(1, -1) for it in self.models])\n",
    "\n",
    "        if return_std:\n",
    "            return np.mean(all_y, axis=0), np.std(all_y, axis=0)\n",
    "        else:\n",
    "            return np.mean(all_y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import tqdm.notebook\n",
    "\n",
    "\n",
    "def swap_monomers(seq):\n",
    "    seq = seq.replace('A', 'C')\n",
    "    seq = seq.replace('B', 'A')\n",
    "    seq = seq.replace('C', 'B')\n",
    "    return seq\n",
    "\n",
    "\n",
    "def make_base(degree, verbose=False):\n",
    "    # construct unique numbers of A/B monomers\n",
    "    base = []\n",
    "    for i in range(degree+1):\n",
    "        for j in range(i):\n",
    "            seq = ''.join(['A' for _ in range(i-j)] + ['B' for _ in range(j)])\n",
    "            base += [''.join(x) for x in itertools.permutations(seq)]\n",
    "            base += [''.join(x) for x in itertools.permutations(swap_monomers(seq))]\n",
    "    base = sorted(set(base))\n",
    "    pruned_base = []\n",
    "    for b in base:\n",
    "        if b not in pruned_base and b[::-1] not in pruned_base:\n",
    "            pruned_base.append(b)\n",
    "    base = pruned_base\n",
    "    if verbose:\n",
    "        print(f'Finding {len(base)} patterns:', base)\n",
    "\n",
    "    return base\n",
    "\n",
    "\n",
    "def featurize(chain_sequences, base, symmetric=False, verbose=False):\n",
    "    x = np.zeros([len(chain_sequences), len(base)])\n",
    "    pbar = tqdm.notebook.tqdm(enumerate(chain_sequences),\n",
    "                              total=len(chain_sequences),\n",
    "                              disable=(not verbose))\n",
    "    for i, chain in pbar:\n",
    "        if 'A' in str(chain):\n",
    "            seq = chain\n",
    "        else:\n",
    "            seq = ''.join(['A' if x == 0 else 'B' for x in chain])\n",
    "        x[i] = np.array([seq.count(b) for b in base])\n",
    "        if symmetric:\n",
    "            x[i] += np.array([seq[::-1].count(b) for b in base])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "base = make_base(degree=6)\n",
    "possible_tokens = featurize(possible_sequences, base, symmetric=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T12:20:17.806464Z",
     "start_time": "2024-08-28T12:20:14.364729Z"
    }
   },
   "id": "e5b68d474c767139"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "batch_prompt = \"Here\\n<result>\\nNote\"  # an empty/fake prompt to facilitate the message_utils\n",
    "AB = {'A': 0, 'B': 1}\n",
    "all_arrs = np.array([[int(x) for x in s] for s in possible_sequences])\n",
    "all_init_arrs = np.array([[int(x) for x in s] for s in possible_init_sequences])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T12:20:25.452518Z",
     "start_time": "2024-08-28T12:20:24.245092Z"
    }
   },
   "id": "a96e5433fc65bb3b"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing results for liquid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.34it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.92it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.02it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.08it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing results for membrane...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.95it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  5.60it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.90it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.06it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing results for spherical micelle...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.25it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.17it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.10it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.91it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing results for string...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  7.08it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.98it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.14it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  5.79it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing results for vesicle...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.36it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  5.96it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  7.04it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.54it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing results for wormlike micelle...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.82it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.89it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.92it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.90it/s]\n",
      "100%|██████████| 9/9 [00:01<00:00,  6.51it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import message_utils, model_utils\n",
    "from target_defs import archetype_predictions, archetype_sequences\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "\n",
    "arch_morphs = list(archetype_predictions.keys())\n",
    "for morph in arch_morphs:\n",
    "    \n",
    "    print(f'computing results for {morph}...')\n",
    "    target = archetype_predictions[morph]\n",
    "    \n",
    "    rollouts = []\n",
    "    \n",
    "    n_batch = 5\n",
    "    n_init = 5\n",
    "    n_total = 10\n",
    "    xi = 1e-2\n",
    "    \n",
    "    use_tokens = False\n",
    "    symmetrize = False\n",
    "    use_seed = True\n",
    "    \n",
    "    params = {'n_batch': n_batch,\n",
    "            'n_init': n_init,\n",
    "            'xi': xi,\n",
    "            'use_tokens': use_tokens,\n",
    "            'symmetrize': symmetrize,\n",
    "            'target': target.tolist(),\n",
    "            'morph': morph,\n",
    "            'use_seed': use_seed}\n",
    "    \n",
    "    start_time = int(time.time())\n",
    "    for ridx in range(5):\n",
    "        fake_payload = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": \"N/A\"}]}]\n",
    "        \n",
    "        rf = EnsembleRFModel(model_params={'random_state': ridx, 'n_estimators': 16, 'max_depth': None}, symmetrize=(symmetrize and not use_tokens))\n",
    "        \n",
    "        rng = np.random.RandomState(ridx)\n",
    "        init_idx = rng.choice(np.arange(len(possible_init_sequences)), n_init, replace=False)\n",
    "        init_bitstr = [possible_init_sequences[it] for it in init_idx]\n",
    "\n",
    "        if use_seed:\n",
    "            init_bitstr[0] = archetype_sequences[morph]\n",
    "        init_sequences = [it.replace('0', 'A').replace('1', 'B') for it in init_bitstr]\n",
    "        \n",
    "        if use_tokens:\n",
    "            x_so_far = featurize(init_sequences, base, symmetric=True)\n",
    "        else:\n",
    "            x_so_far = np.array([[int(AB[x]) for x in s] for s in init_sequences])\n",
    "        \n",
    "        out = model_utils.evaluate_sequences(init_sequences, target, model_ensemble)\n",
    "        fake_payload.append(message_utils.build_user_message(batch_prompt, out))\n",
    "        y_so_far = np.array([float(it.split(':')[1]) for it in out.split('\\n')])\n",
    "\n",
    "        _ = rf.fit(x_so_far, y_so_far)\n",
    "        \n",
    "        is_avail = np.ones(len(possible_sequences)).astype(bool)\n",
    "        for sarr in init_bitstr:\n",
    "            i = np.argwhere(possible_sequences == sarr.replace('A', '0').replace('B', '1')).flatten()[0]\n",
    "            is_avail[i] = False\n",
    "\n",
    "        for _ in tqdm.tqdm(range(n_total-n_init//n_batch)):\n",
    "            \n",
    "            if use_tokens:\n",
    "                mu, sigma = rf.predict(possible_tokens, return_std=True)\n",
    "            else:\n",
    "                mu, sigma = rf.predict(all_arrs, return_std=True)\n",
    "    \n",
    "            o = np.hstack([np.argsort(mu - xi * sigma)])\n",
    "            next_sequences = []\n",
    "            k = 0\n",
    "            while len(next_sequences) < n_batch:\n",
    "                if is_avail[o[k]]:\n",
    "                    next_bitstr = possible_sequences[o[k]]\n",
    "                    seq = next_bitstr.replace('0', 'A').replace('1', 'B')\n",
    "                    next_sequences.append(seq)\n",
    "                    is_avail[o[k]] = False\n",
    "                k += 1\n",
    "            \n",
    "            if use_tokens:\n",
    "                next_x = featurize(next_sequences, base, symmetric=True)\n",
    "            else:\n",
    "                next_x = np.array([[int(AB[x]) for x in s] for s in next_sequences])\n",
    "            x_so_far = np.vstack([x_so_far, next_x])\n",
    "            \n",
    "            out = model_utils.evaluate_sequences(next_sequences, target, model_ensemble)\n",
    "            fake_payload.append(message_utils.build_user_message(batch_prompt, out))\n",
    "            y_so_far = np.hstack([y_so_far, np.array([float(it.split(':')[1]) for it in out.split('\\n')])])\n",
    "            \n",
    "            _ = rf.fit(x_so_far, y_so_far)\n",
    "        \n",
    "        param_hash = message_utils.hash_dict(params)\n",
    "        buffer = {'params': params, 'messages': fake_payload}\n",
    "        suffix = str(ridx)\n",
    "        seed_hash = 'seeded' if use_seed else 'unseeded'\n",
    "        logdir = f'data/llm-logs/{seed_hash}/active/{morph}/'\n",
    "        if not os.path.isdir(logdir):\n",
    "            os.mkdir(logdir)\n",
    "        logfile = os.path.join(logdir, f'active-learning-{param_hash}-{start_time}{suffix}.json')\n",
    "        with open(logfile, 'w') as fid:\n",
    "            json.dump(buffer, fid)\n",
    "\n",
    "        rollouts.append(fake_payload)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-08-28T12:33:46.163008Z",
     "start_time": "2024-08-28T12:33:02.879165Z"
    }
   },
   "id": "a68fe27875fcb33e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "463e24b514993af"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
